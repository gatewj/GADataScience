

    Given the following machine learning matrix, fit each of the following algorithms into their respective places. Some may have multiple.
    . 	            continuous 	            categorical
    supervised 	    regression 	            classification
    unsupervised 	dimension reduction 	clustering

    Algorithms:
        Ordinary Least Squares       Continuous supervised
        Logistic Regression          categorical supervised
        Naive Bayes    unsupervised
        Decision Trees   supervised continuous and categorical
        Support Vector Machines supervised regression
        Nearest Neighbors           clustering
        K Means  unsupervised classification clustering
        Principal Component Analysis (Matrix Decomposition)   unsupervised continuous and categorical

    Given the 4 entities in the matrix above, describe a problem / example we worked on in class for each, and provide one idea on your own.

    regression refers to a problem where we are trying to predict the results within a continuous output

    classification refers to trying to predict a problem within a discrete output. For example, this weekend I worked on an affair database and tried to predict if a women would have an affair or not, based on 1 and 0.

    clustering refers to, the SVM problem we worked on was a clustering problem

    dimension reduction example we worked on was the principal component analysis problem on the iris data set

    All sklearn prediction objects have functions akin to fit(), transform(), predict(), and fit_transform(). Explain each in their most general terms.

    fit() - applies some algorithm to data

    transform() - change the scaling of the data, takes an X and makes a new X

    predict() - return target value (y)

    fit_transform() - apply the fit function then return new X

    score - some metric given (y,y prime)


    Two of the above algorithms can use kernels (in their sklearn context) a. Explain what a kernel does b. Which are the two algorithms that use kernels?

    kernals may be used to help normalize the data, fit the data a certain way.  Support Vector Machines and K means used kernals

    One of the above algorithms is most obviously not a linear solution to classification (it does not draw straight decision lines). Which algorithm is it, and how does it decide on decision lines?

    You are working on microarray (DNA) samples where number of observations (n) is 5 and number of observations (m) is > 10,000.
        Describe a supervised and unsupervised technique in order to reduce the number of features in the samples to those that are most significant.

        Supervised: Lasso (L1) Regression

        Unsupervised:  Principal Component Analysis might be good to use to figure out which features are the most important which is an unsupervised technique, returns the components while maintaining variance

        Compare the two techniques in their solution.

    




    Below is a table of Gini Importance (Normalized to 1) in predicting rent in New York City.
        Which algorithm uses Gini Importance?
        Interpret the table.
    Feature 	Gini Importance
    bedrooms 	        0.211
    bathrooms 	        0.005
    sqft 	            0.532
    distance subway 	0.198
    distance columbus 	0.017
    nearby pizza 	    0.042

    Gini importance describes which variable influences the data the most. The Decision Tree uses the Gini Importance

    What is the Receiving Operator Characteristic Curve? What two metrics is it composed of?
    The ROC is a curve demonstrating true positive rate against false positive rate for different cutpoints of testing.

     
    How does a grid search work? Use an example algorithm from above to help explain it.

    


    Three parts:
        What's your strongest "takeaway" from machine learning and this segment of the course?
        Given a 2 dimensional figure where y=effort to learn and x=immediate usefulness, and slope = 1, what is one algorithm that felt above the slope (more effort to learn than usefulness) and one algorithm that felt below the slope (more usefulness than effort to learn)?
        What's one question you still have about machine learning?
